{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python_CoreyPanda_StackOverFlow_Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import panda library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define df as dataset or dataframe for future callings for csv files\n",
    "df = pd.read_csv('C:/Users/lebad/Desktop/Personal enhancement/Job Enhancement/My projects/PYTHON/survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the dataframe limited rows and columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show a limited cut of data\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows column names, Non-null Counts and data types\n",
    "# object means string, float is decimal and int64 is int\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get and display all 48 columns when running df functions\n",
    "pd.set_option('display.max_columns',48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Schema data file \n",
    "schema_df = pd.read_csv('C:/Users/lebad/Desktop/Personal enhancement/Job Enhancement/My projects/PYTHON/survey_results_schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get and display all 5 columns when running df functions\n",
    "pd.set_option('display.max_columns',48)\n",
    "# To get and display all 85 rows when running df functions\n",
    "pd.set_option('display.max_rows',85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To get and display first 5 rows, () without number gives us 5\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get and display last 10 rows, () without number gives us 5\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the values of one  columns\n",
    "df['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the type of data\n",
    "type('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the type of data in a framework result in pandas.core.series.Series\n",
    "type(df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the data frames column /should be case sensetive\n",
    "df.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access multiple columns/ Casesensetive\n",
    "df[['Age','Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just get the name of olumns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just get the name/value of rows which starts from 0\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just get the name/value of multiple rows/ which starts from 0/you need to use brackets because you are passing a list(more than one)\n",
    "df.iloc[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just get the name/value of row 0,34 and 3 and columns name/values of 0,1,2,3,4 /Using integers for location\n",
    "df.iloc[[0,34,3],[0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just get the name/value of row 0,34 and 3 and columns name/values of 0,1,2,3,4 /Using Labels for location\n",
    "df.loc[[0,34,3,8880],['Age','Gender','Employment','US_State','DevType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the unique value of the data for one columns(like DISTINCT COUNT)/accepts multiple column name as a LIST\n",
    "df['US_State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO get a slice of data/Casesensitive/get a data range\n",
    "df.loc[2:5,'Age':'Accessibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To assign an index to a dataset/ it doesn't changes the original dataset\n",
    "df.set_index('ResponseId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To assign an index to a dataset\n",
    "df.set_index('ResponseId', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reset the index\n",
    "df.reset_index(inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign the data when we get the data we can do it when we load the data in\n",
    "df = pd.read_csv('C:/Users/lebad/Desktop/Personal enhancement/Job Enhancement/My projects/PYTHON/survey_results_public.csv', index_col= 'ResponseId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema_df.loc['Gender','question']\n",
    "#schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter data/ works like a mask for data\n",
    "df['Gender'] == 'Men'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the filtered data you can define a variable and then get the data later/ () is just to seprate two =s\n",
    "filt = (df['Gender'] == 'Man')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the other way to filter\n",
    "df.loc[filt]\n",
    "#df.loc[filt,'Country'] if we want to have data related to filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And and Or & |\n",
    "filt2 = (df['Gender'] == 'Man') & (df['LearnCode'] == 'School') & (df['Country'] == 'Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And and Or & | Have Tilda ~\n",
    "filt3 = (df['Gender'] == 'Man') & (df['LearnCode'] == 'School') & (df['Country'] == 'Brazil')\n",
    "df.loc[filt3,['Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT And and Or & | Have Tilda ~\n",
    "filt4 = (df['Gender'] == 'Man') & (df['LearnCode'] == 'School') & (df['Country'] == 'Brazil')\n",
    "df.loc[~filt4,['Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT And and Or & | Have Tilda ~\n",
    "filt5 = (df['Gender'] == 'Man') & (df['LearnCode'] == 'School') | (df['Country'] == 'Brazil')\n",
    "df.loc[~filt5,['Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT And and Or & | Have Tilda ~\n",
    "filt6 = (df['Gender'] == 'Man') \n",
    "df.loc[~filt6,['Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter a list\n",
    "countries = ['United States of America','Germany','Israel','Norway',]\n",
    "filt7 = df['Country'].isin(countries)\n",
    "df.loc[filt7,['Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter part of a string\n",
    "# na = false is for NaN values to scape them\n",
    "filt8 = df['Employment'].str.contains('Student',na = False)\n",
    "df.loc[filt8,['Employment','Gender','LearnCode','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace or rename all column names you have to have them all in your list\n",
    "# df.columns = ['x','y','z,....']\n",
    "# To change the column names to uppercase/lowe \n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove Spaces\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without inplace it wouldn't change it in dataset\n",
    "df.rename(columns = {'EMPLOYMENT':'Employ'}, inplace= True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace the value\n",
    "df.at[2,'Gender'] = 'Man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace the value\n",
    "filter9 = (df['Gender'] == 'Man')\n",
    "df.loc[filter9 ,'Gender'] = 'Male'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace a column as a lower/upper case\n",
    "df['US_State'] = df['US_State'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['US_State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calling a function on our values\n",
    "df['Country'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the max lenght of the column value\n",
    "df['Country'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define a function\n",
    "def update_Country(Country):\n",
    "    return Country.upper()\n",
    "df['Country'] = df['Country'].apply(update_Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define a function with lambda used with series\n",
    "df['Country'] = df['Country'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define a function with the dataframe/ it will give us the number of rows\n",
    "df.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you number of columns\n",
    "df.apply(len, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the min of columns with numeric value\n",
    "df.apply(lambda x: x.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get lenght for all str values\n",
    "df.applymap(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them all lowercase\n",
    "df.applymap(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To substitue some of our values\n",
    "df['Gender'].map({'Male':'Men'})\n",
    "# It will replace the notmentioned values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To substitue some of our values\n",
    "df['Gender'].replace({'Male':'Men'})\n",
    "# it will not change the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the values in dataset we use this\n",
    "df['Gender']= df['Gender'].replace({'Male':'Men'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'ConvertedCompYearly': 'SalaryUSD'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalaryUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To map Yes and No to Boilean value\n",
    "df['Trans'].map({'Yes': True, 'No':False})\n",
    "df['Trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Trans'] = df['Trans'].map({'Yes': True, 'No':False})\n",
    "df['Trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add or remove columns\n",
    "# To concat two columns\n",
    "df['New Column']= df['Gender']+ '  '+df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop a columns\n",
    "# To make it permanet use inplace\n",
    "df.drop(columns ='New Column', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Split\n",
    "df['New Column'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Split in two columns\n",
    "df['New Column'].str.split(' ',expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Split in two columns in columns\n",
    "df[['Gender1','Age1','3','4','5','6','7','8','9','10','11','12','13','14']]=df['New Column'].str.split(' ',expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a row\n",
    "df.append({'Gender':'WTF'}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To append two dataframe\n",
    "#  df= df.append(df2,ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove a row by index\n",
    "df.drop(index = 83438, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove a row by index by looking for it\n",
    "df.drop(index = df[df['Country']=='Canada'].index, inplace= True)\n",
    "df['Country']\n",
    "# Or have it this way\n",
    "filt76 = df['Country']=='Canada'\n",
    "df.drop(index = df[filt76].index, inplace= True)\n",
    "df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 1 attribute\n",
    "df.sort_values(by = 'Country',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by >1 attribute\n",
    "df.sort_values(by = ['Country','Age'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by >1 attribute\n",
    "df.sort_values(by = ['Country','Age'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by >1 attribute asc and desc\n",
    "df.sort_values(by = ['US_State','UK_Country'],ascending = [False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['US_State'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['US_State','LearnCode']].sort_values(by = 'US_State',ascending = True)\n",
    "df[['US_State','LearnCode']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the 10 largest number\n",
    "df['SalaryUSD'].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nlargest(10,'SalaryUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalaryUSD'].nsmallest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and Aggregating data\n",
    "Median = df['SalaryUSD'].median()\n",
    "Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all numeric numbers\n",
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean = df['SalaryUSD'].mean()\n",
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get aggregated info on numeric data\n",
    "# count is count of non missing values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['SalaryUSD'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the count of value counts\n",
    "df['Trans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OrgSize'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OrgSize'].value_counts(normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by\n",
    "OrgGroup = df.groupby(['OrgSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrgGroup.get_group('20 to 99 employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter does the same\n",
    "filt76 = df['OrgSize'] == '20 to 99 employees'\n",
    "df.loc[filt76]['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more of aggregated\n",
    "df.columns\n",
    "CountryGroup = df.groupby(['Country'])\n",
    "CountryGroup['SalaryUSD'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountryGroup = df.groupby(['Country'])\n",
    "CountryGroup['SalaryUSD'].agg(['median','mean','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To answer : What % of people from each country know coding from school?\n",
    "country_resp = df['Country'].value_counts()\n",
    "country_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#School_df = pd.concat([country_resp,country_sc],axis= 'rows',sort= False)\n",
    "#School_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sc = CountryGroup['LearnCode'].apply(lambda x: x.str.contains('School').sum())\n",
    "country_sc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c326aeec5e9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Note they are without '' /using axis because by default its rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSchool_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountry_resp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcountry_sc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'columns'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSchool_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Note they are without '' /using axis because by default its rows\n",
    "School_df = pd.concat([country_resp,country_sc],axis= 'columns',sort= False)\n",
    "School_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "School_df.rename(columns= {'Country':'Respondants','LearnCode':'LearnInSchool'},inplace= True)\n",
    "School_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "School_df['PCT']=(School_df['LearnInSchool']/School_df['Respondants'])*100\n",
    "School_df.sort_values(by = 'PCT',ascending = False,inplace= True)\n",
    "School_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "School_df.loc['japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean values\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to delet listwise missing value\n",
    "df.dropna()\n",
    "# default values in () are axis= 'index', how='any'\n",
    "df.columns\n",
    "df.dropna(axis= 'index', how='all')\n",
    "# it will drop values that all values are missing\n",
    "# if it says axis='columns' it will drop whole column that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows in a custome attribute\n",
    "df.dropna(axis='index', how='all',subset=['LearnCode'],inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop customized missing values\n",
    "df.replace('NA',np.nan, inplace= True)\n",
    "df.replace('Unknown',np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives us a mask of if a value is missing\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change values\n",
    "df.fillna('MISSING')\n",
    "# To make it perminent use inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NaN is a float underhood\n",
    "type(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cast\n",
    "# df['age'] = df['age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].replace({'25-34 years old':'29','18-24 years old':'22', 'Prefer not to say':'0',\n",
    "       '45-54 years old':'48', 'Under 18 years old':'9', '35-44 years old':'39',\n",
    "       '65 years or older':'70', '55-64 years old':'62', nan]:'0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Age'].replace( nan:'0', inplace=True)\n",
    "\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with Time and Date data\n",
    "# if we have a datetime do as below\n",
    "# if it is not a datetime type we can convert it\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# if you get an error you can give it the format as well\n",
    "# - http://bit.ly/python-dt-fmt\n",
    "# df['Date'] = pd.to_datetime(df['Date'],format = 'Y-%m-%d %I-%p')\n",
    "# get the day name/ df['Date'].day_name()\n",
    "# if you want to get the data from begining as Date use \n",
    "# d_parser = lambda x:pd.datetime.strptime(x, 'Y-%m-%d %I-%p')\n",
    "# df= pd.read_csv('X\\f\\v.csv'. parse_dates= ['Date'],date_parser = d_parser )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to get the dayname\n",
    "# df['Day'] = df['Date'].dt.day_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see earliest and Latest\n",
    "# df['Date'].min()  or .max()\n",
    "# df['Date'].max()-df['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do filters on Date\n",
    "# filt = (df['Date']>'2020')\n",
    "# df.loc[filt]\n",
    "# # filt = (df['Date']>'2020') & (df['Date']<'2022')\n",
    "# df.loc[filt]\n",
    "# filt = (df['Date']>pd.to_datetime('2019-01-01')) & (df['Date']<pd.To_datetime('2022-01-01'))\n",
    "#\n",
    "# df.set_index('Date', inplace= True)\n",
    "# df['2019'] gives you the data for 2019 when you set date as index\n",
    "# df['2020-01':'2020-03']\n",
    "# df['2020-01':'2020-03']['Attribute'].mean()\n",
    "# gives you the average of attribute in the days it has been filtered\n",
    "# http://bit.ly/pandas-dt-fmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To group by hourly dates by day and maximum value \n",
    "#highs = df['Attribute'].resample('D').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.resample('W').mean() gives you the avg for all numeric attributes weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.resample('W').agg({'At1':'mean','At2':'max','At3':'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read and write data from varoius sources\n",
    "# dp = pd.read_xlx(fileaddress, index_col= 'PrimaryKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabdelimitedfiles filt_df.to_csv('address/filename.tsv', sep= '\\t')\n",
    "# For Tabseprated file also pd.read_table(Address on local or on web like 'http://bit.ly/chiporders')\n",
    "# Another example\n",
    "# user_cols = ['userid','age','gender','occupation','zip_code']\n",
    "# users= pd.read_table('http://bit.ly/movieusers', sep='|',header=None , names= user_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export the data frame to csv first filter the data as you wish and name it then\n",
    "# filt_df.to_csv('address/filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write as an Excel you need to pip install\n",
    "# pip install xlwt /for xlx format\n",
    "# pip install xlwt openpyxl / for xlxs format\n",
    "# pip install xlwt openpyxl xlrd / to read xlxs format as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(address/filename.xlxs)\n",
    "# df.to_json(address/filename.json, orient='record',lines= True) to have each record in a line\n",
    "# To get data from DB\n",
    "# first pip install SQLAlchemy \n",
    "# for Postgres\n",
    "# pip install psycopg2-binary\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for postgres first userpass then server,port, and db name\n",
    "#engine= create_engine('postgressql://dbuser:dbpass@localhost:5432/sample_db')\n",
    "#to export to sql: df.to_sql('sample_table',engine, if_exists = 'replace')\n",
    "# we can replace or append or other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "#engine= create_engine('postgressql://dbuser:dbpass@localhost:5432/sample_db')\n",
    "# sql_df = pd.read_sql('sample_table',engine, index_col='At1')\n",
    "## to read a query\n",
    "## sql_df = pd.read_sql_query('select * from sample_table',engine, index_col='At1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to upload data(json) from URL\n",
    "# df = pd.read_json('URLAddress')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
