{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.read_table\n",
    "# pandas.read_table(filepath_or_buffer, sep=NoDefault.no_default, delimiter=None, header='infer',\n",
    "     #             names=NoDefault.no_default, index_col=None, usecols=None, squeeze=None, prefix=NoDefault.no_default, \n",
    "      #            mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None,\n",
    "       #           skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True,\n",
    "        #          na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False,\n",
    "         #         keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None,\n",
    "          #        compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, \n",
    "           #       doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', \n",
    "            #      dialect=None, error_bad_lines=None, warn_bad_lines=None, on_bad_lines=None, delim_whitespace=False,\n",
    "             #     low_memory=True, memory_map=False, float_precision=None, storage_options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd= 'ab'+'df'\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab, df2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd= 'ab'+', '+ 'df'+ str('2')\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more info on a function on Jupyter hit anywhere inside the () and do a SHIFT +Tab once, twice and third and 4th time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods of changing the column header\n",
    "# First : df.rename(columns = {'x1':'x','y1':'y'}, inplace = True)\n",
    "# second : definiing the columns df.col = ['x','y'] then df.columns = df.col\n",
    "# Third : when pulling the data in df.col = ['x','y'] then df= pd.read_csv('address', name=df.col, header = 0)\n",
    "# Forths : mass change like change empty space to _ : df.coloumns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods of removing columns,rows \n",
    "# first : df.drop(['x','y'],axis =1 , inplace = True) axis 0 means rows and axis 1 means column\n",
    "# df.drop([0,1], axis =0 , inplace = True) using index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misssing Value Strategy\n",
    "# 1:drop any rows with null value  df.dropna(how= 'any'or 'all',inplace= True or False)\n",
    "# any means any values are missing with the all it will drop if all values are null\n",
    "# df.dropna(subset = ['x','y'], how = 'any/all')\n",
    "# df.value_counts(dropna= False) gives you count of values including Missing values\n",
    "# df['x'].fillna(value='z',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a boolean attribute to the data frame for movies with duration more than 200\n",
    " # booleans = []\n",
    "    # for lenght in movies.duration:\n",
    "    # if lenght >= 200:\n",
    "    # booleans.append(true)\n",
    "    # else:\n",
    "    # booleans.append(False)\n",
    "    # is_long = pd.Series(boolean)\n",
    "    # Shows the movies that are longer than 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can do this\n",
    "# is_long = movies.duration >=200\n",
    "# is_long.head()\n",
    "# or\n",
    "# movies[movies.duration>=200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies[movies.duration>=200].genre\n",
    "# or # movies[movies.duration>=200]['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter data\n",
    "# movies[(movies.duration>= 200) & (movies.genre == 'Drama')] And condition\n",
    "# movies[(movies.duration>= 200) | (movies.genre == 'Drama')] or condition\n",
    "# movies.genre.isin(['x','y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read a file just limited columns\n",
    "# after import df= pd.read_csv('address',usecols=['x','y','z']) or\n",
    "# df= pd.read_csv('address',usecols=[0:4]) or [0,4]\n",
    "# to read first limited rows before getting it in\n",
    "# df= pd.read_csv('address',usecols=['x','y','z'], nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop every columns that are non-numeric\n",
    "# import numpy as np\n",
    "# df.select_dtypes(include = [np.number]).dtypes\n",
    "# To describe some of special data types\n",
    "# df.describe(include=['object','int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save a test model to Kaggel(Titanic)\n",
    "# train= pd.read_csv('address')\n",
    "# feature_cols = ['x','y']\n",
    "# gs= train.loc[:,features_cols]\n",
    "# u = gs.w\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X,y)\n",
    "# test = pd.read_csv('add2') this file is without Survived Column\n",
    "# test.head()\n",
    "# X_new = test.loc[:, features_cols]\n",
    "# X_new.shape\n",
    "# new_pred_class = logreg.predict(X-new)\n",
    "# new_pred_class\n",
    "# pd.dataFrame({'PassengerId': test.PassengerId, 'Survived':new_pred_class}).set_index('PassengerId').to_csv('FileName')\n",
    "# \n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
